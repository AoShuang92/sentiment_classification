{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "kpMxexWmcxOi",
    "outputId": "6ac70514-f8eb-4f78-809e-03c0760a712f"
   },
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "import pandas\n",
    "from torch.utils.data import Dataset\n",
    "import tqdm\n",
    "import spacy\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import torchvision \n",
    "from torchvision import models, datasets, transforms\n",
    "SEED = 2222\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "#nlp = spacy.load('en')\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = pandas\\\n",
    "            .read_csv('sentiment.tsv',sep='\\t',header=0)\\\n",
    "            .groupby('id')\\\n",
    "            .first()\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if type(idx) is torch.Tensor:\n",
    "            idx = idx.item()\n",
    "        sample = self.data.iloc[idx]\n",
    "        token_vectors = []\n",
    "        for token in nlp (sample.review.lower(),disable = ['parser','tagger','ner']):\n",
    "            token_vectors.append(token.vector)\n",
    "        return (torch.tensor(token_vectors),\n",
    "                torch.tensor(len(token_vectors)),\n",
    "                torch.tensor(sample.sentiment))\n",
    "    \n",
    "def collate(batch):\n",
    "\n",
    "\n",
    "    batch.sort(key=lambda x: x[1], reverse = True)\n",
    "    sequences, lengths, sentiments = zip(*batch)\n",
    "    \n",
    "    sequences = torch.nn.utils.rnn.pad_sequence(\n",
    "        sequences, batch_first=True)\n",
    "    sentiments = torch.stack(sentiments)\n",
    "    lengths = torch.stack(lengths)\n",
    "    return sequences, lengths, sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GD9FvJXVjNoc"
   },
   "outputs": [],
   "source": [
    "class ModelLSTM (torch.nn.Module):\n",
    "    def __init__(self, input_dimensions,size=128,layers=1):\n",
    "        super().__init__()\n",
    "        self.seq = torch.nn.LSTM(input_dimensions,size,layers)\n",
    "        self.layer_one = torch.nn.Linear(size*layers, size)\n",
    "        self.activation_one = torch.nn.ReLU()\n",
    "        self.layer_two = torch.nn.Linear(size, size)\n",
    "        self.activation_two = torch.nn.ReLU()\n",
    "        self.shape_outputs = torch.nn.Linear(size, 2)\n",
    "\n",
    "    def forward(self, inputs,lengths):\n",
    "        number_of_batches = lengths.shape[0]\n",
    "        packed_inputs = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "            inputs,\n",
    "            lengths,\n",
    "            batch_first = True)\n",
    "        buffer,(hidden,cell) = self.seq(packed_inputs)\n",
    "        # the sequence number has the step first not the batch first\n",
    "        # this way to permute the batch first\n",
    "        buffer = hidden.permute(1,0,2)\n",
    "        #flatten out the last hidden state\n",
    "        #this will be the tensor representing the whole batch\n",
    "        #contiguous() -- similar with squeeze \n",
    "        buffer = buffer.contiguous().view(number_of_batches,-1)\n",
    "        \n",
    "        buffer = self.layer_one(buffer)\n",
    "        buffer = self.activation_one(buffer)\n",
    "        buffer = self.layer_two(buffer)\n",
    "        buffer = self.activation_two(buffer)\n",
    "        buffer = self.shape_outputs(buffer)\n",
    "        return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cT4R3dC5RpzV"
   },
   "outputs": [],
   "source": [
    "\n",
    "def valid(model, validationloader):\n",
    "  loss_all = []\n",
    "  with torch.no_grad():\n",
    "      model.eval()\n",
    "      for sequences, lengths, sentiments in validationloader:\n",
    "          results = model(inputs)\n",
    "          loss = loss_function(results, actual)\n",
    "          loss_all.append(loss.item())\n",
    "  return  np.mean(np.array(loss_all))\n",
    "\n",
    "def train(model, trainloader, optimizer, loss_function):\n",
    "  model.train()\n",
    "  epoch_loss = []\n",
    "  for sequences, lengths, sentiments in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        results = model(sequences, lengths)\n",
    "        loss = loss_function(results, sentiments)\n",
    "        epoch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "  return np.mean(np.array(epoch_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 22500 704 79\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7dce8e3bfb91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidationloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6532b7240a0a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, loss_function)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "dataset = SentimentDataset()\n",
    "number_for_validating = int(len(dataset)*0.1)\n",
    "number_for_training = len(dataset) - number_for_validating\n",
    "valid_dataset, train_dataset = torch.utils.data.random_split(dataset,[\n",
    "    number_for_validating,number_for_training])\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset,batch_size =32, shuffle =True,collate_fn = collate)\n",
    "validationloader = torch.utils.data.DataLoader(valid_dataset,batch_size =32, shuffle =True,collate_fn = collate)\n",
    "print(len(valid_dataset),len(train_dataset),len(trainloader),len(validationloader))\n",
    "\n",
    "#model\n",
    "#model = Modeltrain(len(traindataset.ordinals))\n",
    "model = ModelLSTM(dataset[0][0].shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "best_loss = float ('inf')\n",
    "best_epoch = 0\n",
    "for epoch in range(50):\n",
    "    train_loss = train(model, trainloader, optimizer, loss_function)\n",
    "    valid_loss = valid(model, validationloader)\n",
    "    if valid_loss<best_loss:\n",
    "        best_loss=valid_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(modeltrain.state_dict(),'best_model.pt')\n",
    "    print('Epoch:%d, Current_loss:%.4f Best_epoch:%d Best_loss:%.4f'%(epoch,valid_loss,best_epoch, best_loss))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "real or not disaster tweets_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
